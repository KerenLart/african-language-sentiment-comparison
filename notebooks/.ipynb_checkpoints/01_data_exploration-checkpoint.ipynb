{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5bdc3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579091f",
   "metadata": {},
   "source": [
    "## Set up plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05469cd3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=== AFRISENTI DATASET EXPLORATION ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f5ff3f",
   "metadata": {},
   "source": [
    "## Load All Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ee1bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_afrisenti_data():\n",
    "    \"\"\"Load all AfriSenti datasets\"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    # Languages and splits\n",
    "    languages = ['twi', 'hausa']\n",
    "    splits = ['train', 'dev', 'test']\n",
    "    \n",
    "    for lang in languages:\n",
    "        data[lang] = {}\n",
    "        for split in splits:\n",
    "            file_path = f'../data/raw/{lang}_{split}.tsv'\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, sep='\\t')\n",
    "                data[lang][split] = df\n",
    "                print(f\"Loaded {lang} {split}: {df.shape[0]} samples\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb44bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_afrisenti_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317db58d",
   "metadata": {},
   "source": [
    "## EXPLORING DATA STRUCTURE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d0902",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== DATA STRUCTURE EXPLORATION ===\")\n",
    "for lang in ['twi', 'hausa']:\n",
    "    if lang in data and 'train' in data[lang]:\n",
    "        df = data[lang]['train']\n",
    "        print(f\"\\n{lang.upper()} columns: {list(df.columns)}\")\n",
    "        print(f\"Sample data:\")\n",
    "        print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82fec8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== LABEL DISTRIBUTION ANALYSIS ===\")\n",
    "def analyze_labels(data):\n",
    "    \"\"\"Analyze label distributions across languages and splits\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for lang in ['twi', 'hausa']:\n",
    "        if lang not in data:\n",
    "            continue\n",
    "            \n",
    "        results[lang] = {}\n",
    "        total_samples = 0\n",
    "        \n",
    "        print(f\"\\n--- {lang.upper()} ---\")\n",
    "        \n",
    "        for split in ['train', 'dev', 'test']:\n",
    "            if split in data[lang]:\n",
    "                df = data[lang][split]\n",
    "                # Find label column (might be 'label', 'sentiment', etc.)\n",
    "                label_col = None\n",
    "                for col in ['label', 'sentiment', 'target']:\n",
    "                    if col in df.columns:\n",
    "                        label_col = col\n",
    "                        break\n",
    "                \n",
    "                if label_col:\n",
    "                    label_dist = df[label_col].value_counts()\n",
    "                    results[lang][split] = label_dist\n",
    "                    total_samples += len(df)\n",
    "                    \n",
    "                    print(f\"{split}: {len(df)} samples\")\n",
    "                    for label, count in label_dist.items():\n",
    "                        print(f\"  {label}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        print(f\"Total {lang} samples: {total_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083456ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "label_results = analyze_labels(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18971610",
   "metadata": {},
   "source": [
    "## Visualize label distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee9c8f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Label Distribution Across Languages and Splits', fontsize=16)\n",
    "\n",
    "row_idx = 0\n",
    "for lang in ['twi', 'hausa']:\n",
    "    if lang in label_results:\n",
    "        col_idx = 0\n",
    "        for split in ['train', 'dev', 'test']:\n",
    "            if split in label_results[lang]:\n",
    "                ax = axes[row_idx, col_idx]\n",
    "                label_dist = label_results[lang][split]\n",
    "                \n",
    "                # Create bar plot\n",
    "                bars = ax.bar(label_dist.index, label_dist.values)\n",
    "                ax.set_title(f'{lang.capitalize()} {split.capitalize()}')\n",
    "                ax.set_ylabel('Count')\n",
    "                \n",
    "                # Add value labels on bars\n",
    "                for bar in bars:\n",
    "                    height = bar.get_height()\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{int(height)}', ha='center', va='bottom')\n",
    "                \n",
    "                col_idx += 1\n",
    "        row_idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc13f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Sample text inspection\n",
    "print(\"\\n=== SAMPLE TEXTS ===\")\n",
    "for lang in ['twi', 'hausa']:\n",
    "    if lang in data and 'train' in data[lang]:\n",
    "        df = data[lang]['train']\n",
    "        text_col = None\n",
    "        label_col = None\n",
    "        \n",
    "        # Find text and label columns\n",
    "        for col in ['text', 'tweet', 'content']:\n",
    "            if col in df.columns:\n",
    "                text_col = col\n",
    "                break\n",
    "        for col in ['label', 'sentiment', 'target']:\n",
    "            if col in df.columns:\n",
    "                label_col = col\n",
    "                break\n",
    "        \n",
    "        if text_col and label_col:\n",
    "            print(f\"\\n{lang.upper()} samples:\")\n",
    "            for sentiment in df[label_col].unique()[:3]:\n",
    "                sample = df[df[label_col] == sentiment].iloc[0]\n",
    "                print(f\"  {sentiment}: {sample[text_col][:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
